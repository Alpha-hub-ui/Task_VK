# Содержимое проекта
 - **data_preprocessing**
 - **concat_df_with_features.ipynb**
 - **feature_selection.ipynb**
 - **scaler.save**
 - **train.ipynb**
 - **model_ep100**
 - **dataset.py**
 - **models.py**
 - **utils.py**
 - **inference.ipynb**
 - **submission.csv**

# data_preprocessing
В данной папке находятся следующие файлы файлы:  
**train.csv, test.csv и features.csv** - предоставленые файлы для решения задачи  
**train_with_features.csv, test_with_features.csv** - промежуточные результаты полученные с помощью **concat_df_with_features.ipynb**  
**final_train.csv, final_test.csv** - файлы подготовленные для тренировки и тестов

# concat_df_with_features.ipynb
В данном файле реализован процесс объединения train и test файлов с features. Объекты из train и test объединются с объектом из features до которого расстояние километрах является минимальным. 
Также в признаки добавляется столбец distance, который отвечает за разницу между двумя этими точками в км. 
Поскольку данный процесс долгий его промежуточные результаты сохраняются в **train_with_features.csv, test_with_features.csv**  

# feature_selection.ipynb
В данном файле происходит отбор информативных признаков. В начале мы анализируем набор данных на наличие дубликаотв и удаляем их.
Далее удаляем сильнокоррелирующие признаки (>0.8).
После проводится работа с выбросами. На основании анализа графиков и z_score выбросы в некоторых столбцах заменены на медианные значения.
Далее с использованием MinMaxScaler проводится нормализация столбцов 'lat', 'lon', 'distance' (предполагается, что остальные нормализованы, поскольку находятся в промежутке от 0 до 1).
Обученый MinMaxScaler сохраняется в **scaler.save**.
Далее проводится отбор признаков с помощью дерева решений, в результате чего в датасете остаается 50 параметров для обучения.
Оставшиеся признаки сохраняются в файлы **final_train.csv, final_test.csv**  

# train.ipynb
В данном файле запускается обучение модели. В начале, для подбора гиперпараметров, модель тренируется с помощью k-fold(Поскольку небыло тренировочного набора данных), 
а после обучается на всем наборе данных и сохраняется в файле **model_ep100**.
Сама модель находится в файле **models.py** и представляет из себя простую полносвязную сети с двумя линейными слоями, dropout и функцией активации relu.
Dataset прописан в файле **dataset.py**, а процесс тренировки описан в функции в файле **utils.py**.

# inference.ipynb
В данном файле реализован процесс предсказания модели score по входным данным и генерация **submission.csv**
